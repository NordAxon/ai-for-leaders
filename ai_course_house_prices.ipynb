{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ai_course_house_prices.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/NordAxon/AI-For-Leaders/blob/master/ai_course_house_prices.ipynb","timestamp":1545254214347},{"file_id":"https://github.com/NordAxon/AI-For-Leaders/blob/master/ai_course_house_prices_3.ipynb","timestamp":1544798748735},{"file_id":"https://github.com/NordAxon/AI-For-Leaders/blob/master/ai_course_house_prices_2.ipynb","timestamp":1540462723617},{"file_id":"https://github.com/NordAxon/AI-For-Leaders/blob/master/ai_course_house_prices.ipynb","timestamp":1539890372780}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"ai_course_env","language":"python","name":"course_env"}},"cells":[{"metadata":{"colab_type":"text","id":"unUCaszMfGHd"},"cell_type":"markdown","source":["#BASIC INFORMATION (ReadMe)\n","\n"]},{"metadata":{"colab_type":"text","id":"4pqCFgd59HDe"},"cell_type":"markdown","source":["**1.  About Jupyter Notebook and Google Colab**\n","- Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning etc.\n","- Google Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud. \n","\n","**2.   About this lab**\n","\n","- In this lab we will explore and use Melbourne housepricing dataset.  Each row in the dataset is a housing sale and columns are the features of the sold house/appartment.\n","\n","\n","- The goal is to predict the price of new sales. We will build two supervised models: regression models and artificial neural network. ML pipeline outlined in the theory part of the course will be followed. \n","\n","\n","**3.  How to save own version of the Jupyter notebook**\n","\n","Go to File and choose \"Save a copy in Drive\". It will be saved on your Google Drive.\n","\n","**4.   How to run/execute cell of code**\n","\n","Mark the cell,  press \"Run\" button on the left side of the cell or Ctrl+Shift tab through the code.\n","\n","\n","**5.  More info about dataset**\n"," - Data source: https://www.kaggle.com/anthonypino/melbourne-housing-market\n","\n","\n"," - Columns:\n","1. Suburb: Suburb\n","2. Address: Address\n","3. Rooms: Number of rooms\n","4. Price: Price in Australian dollars, AUD\n","5. Method: S - property sold; SP - property sold prior; PI - property passed in; PN - sold prior not disclosed; SN - sold not disclosed; NB - no bid; VB - vendor bid; W - withdrawn prior to auction; SA - sold after auction; SS - sold after auction price not disclosed. N/A - price or highest bid not available.\n","6. Type: br - bedroom(s); h - house,cottage,villa, semi,terrace; u - unit, duplex; t - townhouse; dev site - development site; o res - other residential.\n","7. SellerG: Real Estate Agent\n","8. Date: Date sold\n","9. Distance: Distance from CBD in Kilometres \n","10. Regionname: General Region (West, North West, North, North east ...etc)\n","11. Propertycount: Number of properties that exist in the suburb\n","12. Bedroom2 : Scraped # of Bedrooms (from different source)\n","13. Bathroom: Number of Bathrooms\n","14. Car: Number of carspots\n","15. Landsize: Land Size in Metres\n","16. BuildingArea: Building Size in Metres\n","17. YearBuilt: Year the house was built\n","18. CouncilArea: Governing council for the area\n","19. Lattitude: Self explanitory\n","20. Longtitude: Self explanitory\n"]},{"metadata":{"colab_type":"text","id":"GxQPuTJZvTgJ"},"cell_type":"markdown","source":["#1) CLONE ENVIRONMENT & IMPORT LIBRARIES"]},{"metadata":{"colab_type":"text","id":"znqzyheRvdbX"},"cell_type":"markdown","source":["##1.1. Get all the files\n","- Run the below code cell if the notebook is opened in Google Collab. It will clone the github repository to get all necessary files."]},{"metadata":{"colab_type":"code","id":"LsbGyPMrfGHk","colab":{}},"cell_type":"code","source":["!git clone https://github.com/NordAxon/AI-For-Leaders.git"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"9eWT63iMfGHs"},"cell_type":"markdown","source":["## 1.2 Import libraries\n","- ML with Python offers a great deal of libraries.\n","- Read about some of the most used: https://hackernoon.com/top-10-libraries-in-python-to-implement-machine-learning-12602cf5dc61\n","\n","- Lets import all the libraries we need to run the code and perform the analysis. Run the below code cell."]},{"metadata":{"colab_type":"code","id":"I_M2OQmuv4qb","colab":{}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn import linear_model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.datasets import make_regression\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasRegressor\n","\n","import seaborn as sns\n","\n","pd.set_option('display.max_columns', 100)\n","%load_ext autoreload\n","%autoreload 2\n","\n","np.random.seed(1)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"55zikYrPw_V0"},"cell_type":"markdown","source":["# 2) IMPORT RAW DATA"]},{"metadata":{"colab_type":"code","id":"ko97OSflfGHy","colab":{}},"cell_type":"code","source":["housing_df_original = pd.read_csv('AI-For-Leaders/data/melbourne-housing-market/Melbourne_housing.csv')\n","housing_df_original"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"OKO3iwwefGH1","colab":{}},"cell_type":"code","source":["# Size of the dataset (X, Y)\n","housing_df_original.shape"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"UoOdOB70fGH4"},"cell_type":"markdown","source":["# 3) EXPLORE DATA & PRE-PROCESSING"]},{"metadata":{"colab_type":"text","id":"4ANxdz-a_4YI"},"cell_type":"markdown","source":["##  3.1. Fill in empty/missing data\n","\n","- In some of the columns we have NaN(Not a Number) values i.e. missing data.\n","\n","- Many ML algorithms need data in all rows and columns so the NaNs have to be filled with something meaningful. E.g. \"Landsize\" will be filled with 0 to indicate that there is no land contained in the real estate sale. \n","\n","\n","\n"," \n"]},{"metadata":{"colab_type":"text","id":"YDW8L9n6H4td"},"cell_type":"markdown","source":["Let's first have a look at how many NaN values are present in each column. \n","- Run the code cell below"]},{"metadata":{"colab_type":"code","id":"7QzV0cPDfGH7","colab":{}},"cell_type":"code","source":["print('Number of NaNs for every variable:')\n","print(pd.isnull(housing_df_original).sum())"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"JtbVw15XfGH-"},"cell_type":"markdown","source":["Lets clean and fill/replace missing/odd values\n","- Remove rows where there is no price\n","- Fill NaN values in columns BuildingArea, Rooms, Landsize, Car, Bathroom, Bedroom2 with 0\n","- For column YearBuilt, fill with the mean value of that column since the house being built at year 0 seems unlikely"]},{"metadata":{"colab_type":"code","id":"q6LjBN5zfGH_","colab":{}},"cell_type":"code","source":["housing_df_no_nan = housing_df_original.copy()\n","\n","# Remove all rows with no price data\n","housing_df_no_nan = housing_df_no_nan[pd.notnull(housing_df_no_nan['Price'])]\n","\n","# Replace NaN values with 0 values in columns BuildingArea, Rooms, Landsize, Car, Bathroom, Bedroom2 \n","housing_df_no_nan['BuildingArea'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Rooms'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Landsize'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Car'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Bathroom'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Bedroom2'].fillna(0.0, inplace=True)\n","\n","# Replace NaN values in YearBuilt column with mean value of that column\n","housing_df_no_nan['YearBuilt'].fillna(housing_df_no_nan['YearBuilt'].mean(), inplace=True)\n","\n","print('Number of NaNs for every variable:')\n","print(pd.isnull(housing_df_no_nan).sum())"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"PHbIauHMfGID"},"cell_type":"markdown","source":["##**3.2. Plot variable correlations and histograms**\n","\n","- Let's have a look at how different variables relate to each other and how the data is distributed. \n","- The goal is to get insight in our dataset, understand how different columns relate to each other and look for outliers.\n","- Let pick some columns(variables) we think might be good predictors of price and scatter plot those against each other and as histograms along the diagonal. In a real project we would have plotted all variables in many different ways, but we try to restrict the time spent on this by only picking six variables.\n"]},{"metadata":{"colab_type":"code","id":"mHq6CgV6fGIF","colab":{}},"cell_type":"code","source":["plot_str_arr = ['BuildingArea', 'Rooms', 'Landsize', 'Car', 'Bathroom', 'Price']\n","f, axarr = plt.subplots(2, len(plot_str_arr), figsize=(22,7))\n","\n","i = 0\n","for plt_str in plot_str_arr:\n","    sns.regplot(x=plt_str, y=\"Price\", data=housing_df_no_nan, ax=axarr[0,i])\n","    housing_df_no_nan[plt_str].hist(ax=axarr[1,i])\n","    i += 1\n","axarr[1,5].set_ylim([0,7000])\n","f.canvas.set_window_title('Scatter Plots and Histograms')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"bB2QMBvjfGIJ"},"cell_type":"markdown","source":["## 3.3. Remove outliers\n","\n","- Outliers are datapoints located far from the other data points, these come with a risk of skewing the models and therefore we want to remove these. \n","\n","- In the plots above it seems like we have outliers in some of the columns. We will have a deeper look at some columns which seem to contain outliers. \n","\n","- Run the cell below to see a plot of BuildingArea vs Price where it is clear that we have some data points which are far away from the others. "]},{"metadata":{"colab_type":"code","id":"Z93dzDhSfGIJ","colab":{}},"cell_type":"code","source":["housing_df_no_nan.plot.scatter('BuildingArea', 'Price', title='Price [AUD] vs. Building Area [m^2]')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"wH5Dfrv3fGIN"},"cell_type":"markdown","source":["1.   Set clip-offs:\n",">*  Building area = 500 m^2 (all data points larger than 500 will be set to 500)\n",">*  Price= 4 000 000 AUD\n","2. Plot again! "]},{"metadata":{"colab_type":"code","id":"vEHINI-YfGIO","colab":{}},"cell_type":"code","source":["housing_clipped = housing_df_no_nan.copy()\n","housing_clipped['BuildingArea'] = housing_clipped['BuildingArea'].clip(0, 500)\n","housing_clipped['Price'] = housing_clipped['Price'].clip(0, 4e6)\n","housing_clipped.plot.scatter('BuildingArea', 'Price', title='Price [AUD] vs. Building Area [m^2]')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"YPBN0qR9fGIR"},"cell_type":"markdown","source":["### ASSIGNMENT 1:\n","\n","-  Plot \"Landsize\" (unit=m^2) vs \"Price\" in the empty cell below. \n","- Does it look like there are some outliers? If so, what could be a resonable cut-off? (Hint: Have a look above at the statistical printouts for Landsize)\n","-  Clip the data set to remove Landsize outliers, i.e replace the value of variable landsize_max with a resonable number. Plot again!"]},{"metadata":{"colab_type":"code","id":"XgY2E-2JfGIS","colab":{}},"cell_type":"code","source":["# ENTER CODE HERE\n","\n","\n","# SOLUTION (filter out or clip outliers for Landsize)\n","housing_clipped.plot.scatter('Landsize', 'Price', title='Price vs. Landsize')\n","landsize_max = 800\n","housing_clipped_l = housing_clipped.copy()\n","housing_clipped_l['Landsize'] = housing_clipped['Landsize'].clip(0, landsize_max)\n","housing_clipped_l.plot.scatter('Landsize', 'Price', title='Price [AUD] vs. Landsize [m^2]')\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"-JPpakbEfGIZ"},"cell_type":"markdown","source":["## 3.4 Plot histograms for indicative columns\n","- Lets have a look more closely at the variables we think could be interesting by plotting seperate and larger histograms."]},{"metadata":{"colab_type":"code","id":"7sNLlcJufGIa","colab":{}},"cell_type":"code","source":["\n","housing_clipped_l['BuildingArea'].hist(bins=40, figsize=(10,7))\n","plt.title('Histogram of Building Areas');\n","# TODO: Make it better"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"ed036kDmfGIc"},"cell_type":"markdown","source":["### ASSIGNMENT 2:\n","\n","- Create a histogram of variable Price in the empty cell below."]},{"metadata":{"colab_type":"code","id":"rQsuhsmpfGIe","colab":{}},"cell_type":"code","source":["# CODE HERE\n","\n","\n","# SOLUTION\n","housing_clipped_l['Price'].hist(bins=40, figsize=(10,7))\n","plt.title('Histogram of Price');"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"OEcuxYO6fGIi"},"cell_type":"markdown","source":["## 3.5 Price for different regions\n","- We are also hypothesising that the property location will have an impact on price. \n","- Below a plot will be made to get a feel for how different locations might affect the price. "]},{"metadata":{"colab_type":"code","id":"fS01K03AfGIk","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(10,7))\n","housing_clipped_l.groupby('Regionname')['Price'].mean().plot.bar();"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"jvYrjgnNfGIp"},"cell_type":"markdown","source":["### ASSIGNMENT 3: \n","- Plot Price for different CouncilArea"]},{"metadata":{"colab_type":"code","id":"w2C7FLWqfGIq","colab":{}},"cell_type":"code","source":["# CODE HERE\n","\n","# SOLUTION\n","plt.figure(figsize=(10,7))\n","housing_clipped_l.groupby('CouncilArea')['Price'].mean().plot.bar();"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"IPLyTEaxfGIu"},"cell_type":"markdown","source":["# 4) BUILD/TRAIN MODEL: SIMPLE DIMENSIONAL LINEAR REGRESSION\n","\n","- We are getting a feeling for what the data looks like, so now we might try a first model for predicting price. \n","- The simple linear regression, one predictor variable (X) and one output variable (Y)  is very commonly used model. \n","\n","- We pick BuildingArea as a predictor to begin with since there seem to be a correlation between BuildingArea and Price according to our exploration. \n","\n","- The goal is to find all of the weights, $w_i$, in the following linear regression model. **Lookup slide XXXX for better explanation!!!!**\n","\n","\n","> $y = w_0 + w_1x_1$\n","\n","\n","\n","\n","\n"]},{"metadata":{"colab_type":"text","id":"7wmuh5WnyGMU"},"cell_type":"markdown","source":["## 4.1 Split dataset, pick algorithm, train model\n","\n"]},{"metadata":{"colab_type":"code","id":"uFoS970OfGIv","colab":{}},"cell_type":"code","source":["# Set up input (x) and output (y) variables\n","x = housing_clipped_l[['BuildingArea']]\n","y = housing_clipped_l['Price']\n","\n","# Split into test and train data\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n","\n","# Set up and train simple linear regression model\n","regr = linear_model.LinearRegression()\n","regr.fit(x_train, y_train)\n","\n","# Perform predictions on testset\n","y_pred_simple = regr.predict(x_test)\n","\n","print (y_pred_simple)\n","\n","\n","### Plot results ###\n","\n","# Prepare plotting figure and axes\n","plt.figure(figsize=(15,10));\n","plt.title('Simple Linear Regression Model');\n","plt.xlabel('BuildingArea [m^2]', fontsize=10)\n","plt.ylabel('Price [AUD]', fontsize=10)\n","\n","# Plot training data in green color\n","plt.scatter(x_train.values, y_train.values, color='green', alpha=0.2)\n","# Plot test data in red color\n","plt.scatter(x_test.values, y_test.values, color='red', alpha=0.2)\n","\n","# Plot the simple regression line based on test data in blue color\n","plt.plot(x_test, y_pred_simple, 'b')\n","\n","print (regr.coef_)\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"TnYXFGcMfGIz"},"cell_type":"markdown","source":["## 4.2 Model evaluation\n","The error value will be compared to a baseline error which is the error if the prediction is just the mean of previous house values. "]},{"metadata":{"colab_type":"code","id":"g8RVKZ_LfGIz","colab":{}},"cell_type":"code","source":["# Evaluate Results\n","\n","mean_absolute_error_simple = str(int((y_pred_simple - y_test).abs().mean()))\n","mean_baseline_error = str(int((y_train.mean() - y_test).abs().mean()))\n","\n","\n","\n","print('* EVALUATION: Mean Absolute Error with Simple Linear Regression = ' + mean_absolute_error_simple)\n","print('* EVALUATION: Mean Baseline Error: ' + mean_baseline_error)\n","\n","if mean_absolute_error_simple < mean_baseline_error:\n","    print ('\\nMean Absolute Error with \"Simple Linear Regression\" is smaller then \"Mean Baseline Error\". Good!')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"BlVURIwtfGI3"},"cell_type":"markdown","source":["# 5) BUILD/TRAIN MODEL: MULTI-DIMENSIONAL LINEAR REGRESSION\n","\n","- In order to increase the predictive power, i.e. to get a more accurate model, more information can be added to the model. \n","- One way of doing that is by adding more input variables to the model. \n","- Variables that could be tried are BuildingArea, Rooms, LandSize, Car. \n","\n","\n","> $y = w_0 + w_1x_1 + w_2x_2 + \\dots$\n"]},{"metadata":{"colab_type":"text","id":"7eE0As8E0NoT"},"cell_type":"markdown","source":["## 5.1 Split dataset, pick algorithm, train model"]},{"metadata":{"colab_type":"code","id":"v1q5lPyTfGI6","colab":{}},"cell_type":"code","source":["# Pick our in-variables i.e. features\n","features_input_list = ['BuildingArea', 'Rooms','Landsize', 'Car']\n","x = housing_clipped_l[features_input_list]\n","y = housing_clipped_l['Price']\n","\n","# Split into test and train data\n","x_train_multidim, x_test_multidim, y_train_multidim, y_test_multidim = train_test_split(x, y, test_size=0.2)\n","\n","# Set up and train regression model\n","regr_multidim = linear_model.LinearRegression()\n","regr_multidim.fit(x_train_multidim, y_train_multidim)\n","\n","# Perform predictions\n","y_pred_multidim = regr_multidim.predict(x_test_multidim)\n","\n","######### Plot results ##########\n","\n","# Prepare plotting figure and axes\n","plt.figure(figsize=(15,10));\n","plt.title('Multidimensional Linear Regression Model');\n","plt.xlabel('BuildingArea [m^2]', fontsize=10)\n","plt.ylabel('Price [AUD]', fontsize=10)\n","\n","# Plot training data in green color\n","plt.scatter(x_train_multidim['BuildingArea'].values, y_train_multidim.values, color='green', alpha=0.2)\n","# Plot test data in red color\n","plt.scatter(x_test_multidim['BuildingArea'].values, y_test_multidim.values, color='red', alpha=0.2)\n","\n","# Plot the multidim regression line based on test data in black color\n","plt.plot(x_test_multidim['BuildingArea'], y_pred_multidim, 'k.')\n","#plt.plot(x_test_multidim['BuildingArea'], y_pred_simple, 'b')\n","\n","\n","# Print regression coefficients, w\n","print('***** Regression Coefficients: *****')\n","i=0\n","print(len(features_input_list))\n","while i<len(features_input_list):\n","    print(features_input_list[i] + ' = ' + str(regr_multidim.coef_[i]))\n","    i+=1\n","\n","\n","\"\"\"\n","print x_test['BuildingArea'].shape\n","print y_pred_multidim.shape\n","print x_test['BuildingArea']\n","print y_pred_multidim\n","\n","# Transform data\n","scaler = MinMaxScaler()\n","x_train_scaled = scaler.fit_transform(x_train)\n","x_test_scaled = scaler.transform(x_test)\n","y_train_scaled = scaler.fit_transform(y_train.values.reshape(len(y_train),1))\n","y_test_scaled = scaler.transform(y_test.values.reshape(len(y_test),1))\n","\n","print x_train_scaled\n","print y_train_scaled\n","\"\"\""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"wqXs0nUhfGI-"},"cell_type":"markdown","source":["## 5.2 Model evaluation"]},{"metadata":{"colab_type":"code","id":"N9aYkhUxfGI_","colab":{}},"cell_type":"code","source":["mean_absolute_error_multidim = str(int((y_pred_multidim - y_test_multidim).abs().mean()))\n","print('* EVALUATION: Mean Absolute Error with Multi-Dimensional Linear Regression = ' + mean_absolute_error_multidim)\n","print('* EVALUATION: Mean Absolute Error with Simple Linear Regression = ' + mean_absolute_error_simple)\n","\n","if mean_absolute_error_multidim < mean_absolute_error_simple:\n","    print ('\\n Mean Absolute Error with \"Multi-Dimensional Linear Regression\" is smaller then with \"Simple Linear Regression\". \\n Good, our regression model is improving!')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"cbnGfn6ufGJB"},"cell_type":"markdown","source":["## ASSIGNMENT 4:\n","- Test your multidimensional model with different input parameters by picking them from the list of 20 available and compare results? \n","\n",">-->  **Hint**: Modify 2nd line of code in section 5.1, add/remove features in features_input_list. Rerun the model and evaluate!\n","\n"]},{"metadata":{"colab_type":"text","id":"FMi7dYXRfGJC"},"cell_type":"markdown","source":["# 6) BUILD/TRAIN MODEL: ARTIFICAL NEURAL NETWORK\n"]},{"metadata":{"colab_type":"text","id":"pthSByV35oL7"},"cell_type":"markdown","source":["## 6.1 Split dataset, pick algorithm, train & evaluate model\n","\n","The code in the following cell transforms data, builds a neural network and evaluates results of predictions from the neural net.\n","\n","Good reading about different steps with Keras:\n","https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"]},{"metadata":{"colab_type":"code","id":"mIZj-9n2fGJI","colab":{}},"cell_type":"code","source":["# from numpy.random import seed\n","# seed(1)\n","# Filter out the wanted columns\n","\n","def run_neural_network(x, y, n_epochs=10, layer_list=[100,20]):\n","    x_train_nn, x_test_nn, y_train_nn, y_test_nn = train_test_split(x, y, train_size=0.5, test_size=0.5)\n","\n","    # Scale the data\n","    scaler = MinMaxScaler()\n","    x_train_nn = scaler.fit_transform(x_train_nn)\n","    x_test_nn = scaler.transform(x_test_nn)\n","    y_train_nn = scaler.fit_transform(y_train_nn.values.reshape(len(y_train_nn),1))\n","    y_test_nn= scaler.transform(y_test_nn.values.reshape(len(y_test_nn),1))\n","   \n","    # Define the NN structure (with Keras): 3 layers with (100,20,1) neurons, train.shape[1] input variables\n","    model = Sequential()\n","    model.add(Dense(layer_list[0], input_dim=x_train_nn.shape[1], activation='relu'))\n","    for layer_size in layer_list[1:]:\n","        model.add(Dense(layer_size, activation='relu'))\n","    model.add(Dense(1, activation='linear'))\n","    \n","    # Plot model summary\n","    print(model.summary())\n","    \n","    # Compile model \n","    model.compile(loss='mse', optimizer='adam', metrics=['mean_squared_error', 'mean_absolute_error'])\n","\n","    # Train the model\n","    history = model.fit(x_train_nn, y_train_nn, epochs=n_epochs, verbose=0, validation_data=(x_test_nn, y_test_nn))\n","\n","    # Make a prediction\n","    y_pred_nn = model.predict(x_test_nn)[:,0]\n","    \n","    # Show the inputs and predicted outputs\n","    y_pred_nn = scaler.inverse_transform(y_pred_nn.reshape(len(y_pred_nn),1))\n","    y_test_nn = scaler.inverse_transform(y_test_nn)\n","\n","    # Evaluate results\n","    mean_error = (pd.Series(y_pred_nn[:,0]) - y_test_nn[:,0]).abs().mean()\n","    print('EVALUATION: Mean Absolute Test Error: ' + str(mean_error))\n","\n","    # Plot error over training time\n","    plt.figure(figsize=(10,7))\n","    plt.plot(history.history['mean_squared_error'])\n","    plt.plot(history.history['val_mean_squared_error'])\n","    plt.title('Model Loss')\n","    plt.ylabel('Mean Squared Error')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.show()\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"_HacFgP8D0sS","colab_type":"text"},"cell_type":"markdown","source":["## 6.2 Run NN model:"]},{"metadata":{"colab_type":"code","id":"A4iIv_dbt48y","colab":{}},"cell_type":"code","source":["# Pick in-variables i.e. features\n","features_input_list = ['BuildingArea', 'Rooms', 'Landsize', 'Car']\n","x = housing_clipped_l[features_input_list]\n","y = housing_clipped_l['Price']\n","\n","# Call/execute neural network\n","run_neural_network(x,y, 10, [5, 2])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AzKVwfFVaXv1","colab_type":"text"},"cell_type":"markdown","source":["**ASSIGNMENT 5:**\n","*  Try different number of training epochs by adjusting the code above.\n","*   What happens with the loss for a higher amount of training epochs(time)?\n","\n","\n","\n","\n"]},{"metadata":{"colab_type":"text","id":"zDM8gYfIfGJP"},"cell_type":"markdown","source":["## 6.3 Improving NN model\n","Adding more features:\n","- Let's look at the data to see what we can do with the data to create columns which are more easily readable for a ML algorithm and how we can provide more information from the data we have. \n","- Lets try and make the predictive model as good as possible by adding more features such as location and age of property. "]},{"metadata":{"colab_type":"text","id":"yXWtQLXBfGJV"},"cell_type":"markdown","source":["### 6.3.1 Add feature: House age\n","- Using the build year of a house directly as a feature is not good since most values will be around 2000. \n","- A small difference in feature might be a big difference in actual house value; e.g. a house built 2017 is probably a lot more valuable than a house build 2007, but that is still a small percentual difference. The percentual difference between the age of 1 year and 11 years on the other hand gives a large difference. \n","- We also log-transform the age to make it a bit more convenient for machine learning algorithms. "]},{"metadata":{"colab_type":"code","id":"0VpLD8eNfGJW","colab":{}},"cell_type":"code","source":["year_built = housing_clipped_l['YearBuilt'].clip(0, 2018)\n","house_ages = pd.Series(np.log((1 + (2018. - year_built))))\n","house_ages = house_ages.fillna(house_ages.mean())\n","house_ages.name = 'Age'\n","plt.figure()\n","house_ages.hist()\n","plt.title('Distribution After logarithm')\n","house_ages_df = pd.DataFrame(house_ages)\n","features_w_age = pd.concat([housing_clipped_l, house_ages_df], axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2edkqykLE7xs","colab_type":"text"},"cell_type":"markdown","source":["Run the model with house age added."]},{"metadata":{"colab_type":"code","id":"Eprq5-apfGJe","colab":{}},"cell_type":"code","source":["age_feature_list = ['BuildingArea', 'Rooms', 'Landsize', 'Car'] + ['Age'] # + list(one_hot_region.columns)\n","\n","run_neural_network(features_w_age[age_feature_list], features_w_age['Price'])"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"nYFsez2pfGJT"},"cell_type":"markdown","source":["### 6.3.2 Add feature: Regionname \n","Add Regionname as a feature by transforming it to one-hot"]},{"metadata":{"colab_type":"code","id":"1MHW2RhCfGJQ","scrolled":true,"colab":{}},"cell_type":"code","source":["# One-hot encoding of Region\n","one_hot_region = pd.get_dummies(housing_clipped_l.Regionname, prefix='Regionname')\n","region_feature = pd.concat([housing_clipped_l, one_hot_region], axis=1)\n","region_feature"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8t5hupULL6YT","colab_type":"text"},"cell_type":"markdown","source":["Train network with Regionname added"]},{"metadata":{"id":"73i-B5LMLCkN","colab_type":"code","colab":{}},"cell_type":"code","source":["age_feature_list = ['BuildingArea', 'Rooms', 'Landsize', 'Car'] + list(one_hot_region.columns)\n","\n","run_neural_network(region_feature[age_feature_list], region_feature['Price'])"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"LaJnbTnufGJM"},"cell_type":"markdown","source":["### ASSIGNMENT 5:\n","Try different number of training epochs by adjusting the code above.\n","-  What happens with the loss for a higher amount of training epochs(time)?\n"]},{"metadata":{"colab_type":"text","id":"I0Gi_lC-EXqd"},"cell_type":"markdown","source":["ANSWER HERE (doubleclick):\n"]},{"metadata":{"colab_type":"text","id":"9-_uudj12BqX"},"cell_type":"markdown","source":["\n","### ASSIGNMENT 6:\n","Try different sizes of the network by adjusting the code above. Try out the below network configurations and observe the mean absolute error for test and train data.The lists below are denoted such that the first entry represents the number of neurons in the first layer and so on. \n","\n","1.   Configuration 1: [5, 2]\n","2.   Configuration 2: [100, 20]  (increasing the number or neurons)\n","3.   Configuration 3: [1000, 100] (increasing the number or neurons even more)\n","4.   Configuration 4: [5, 5, 5, 2] (more layers, the term deep learning originates from using many layers)\n","5    Configuration 5: [500, 500, 200] (larger network)\n","6.   Configuration 6: Test your own configuration if you want to.  \n","\n","\n","--> **Hint:** Modify 7th line of code under section 6.2.\n","\n","**6.1**. What are the results when adding more layers? <br>\n","**6.2**. What are the results when adding more neurons? <br>\n","**6.3** When is there a difference between train and test data in absolute error? "]},{"metadata":{"colab_type":"text","id":"2WRcSPkFEk0z"},"cell_type":"markdown","source":["ANSWER HERE (doubleclick):"]},{"metadata":{"colab_type":"text","id":"EBj5rJHO2FM5"},"cell_type":"markdown","source":["### ASSIGNMENT 7: \n","Trying adding more features  by adjusting the code above.\n","-  Which columns could be useful for providing more predictive power?"]},{"metadata":{"colab_type":"text","id":"MxXPlM7WEqV_"},"cell_type":"markdown","source":["ANSWER HERE (doubleclick):"]},{"metadata":{"colab_type":"text","id":"8BEJR_BdfGJO"},"cell_type":"markdown","source":["# *DISCUSSION QUESTIONS:*\n","\n","\n","1.   Which of the different models performed best? Why?\n","2.   Why does a well tuned neural network perform better than a linear regression model?\n","3.   What could be done to increase predictive power?\n","4.   Which additional data do you think would make a large differce in predictive power?\n","5.   What was the lowest mean square error you got?\n","\n","\n"]},{"metadata":{"colab_type":"text","id":"hNUBr3uaEzIr"},"cell_type":"markdown","source":["ANSWER HERE (doubleclick):\n","\n","1. \n","2. \n","3. \n","4. \n","5. \n","\n","\n"]}]}